diff --git a/equi_diffpo/common/robomimic_util.py b/equi_diffpo/common/robomimic_util.py
index 030cc2e..e52e2dc 100644
--- a/equi_diffpo/common/robomimic_util.py
+++ b/equi_diffpo/common/robomimic_util.py
@@ -38,7 +38,7 @@ class RobomimicAbsoluteActionConverter:
             render_offscreen=False,
             use_image_obs=False, 
         )
-        assert not abs_env.env.robots[0].controller.use_delta
+        assert not abs_env.env.robots[0].controller.use_relative
 
         self.env = env
         self.abs_env = abs_env
diff --git a/equi_diffpo/config/task/mimicgen_rel.yaml b/equi_diffpo/config/task/mimicgen_rel.yaml
index 5d96920..811dcf8 100644
--- a/equi_diffpo/config/task/mimicgen_rel.yaml
+++ b/equi_diffpo/config/task/mimicgen_rel.yaml
@@ -26,10 +26,10 @@ env_runner:
   dataset_path: ${dataset_path}
   shape_meta: *shape_meta
   n_train: 6
-  n_train_vis: 2
+  n_train_vis: 0
   train_start_idx: 0
   n_test: 50
-  n_test_vis: 4
+  n_test_vis: 0
   test_start_seed: 100000
   max_steps: ${get_max_steps:${task_name}}
   n_obs_steps: ${n_obs_steps}
@@ -40,7 +40,7 @@ env_runner:
   past_action: ${past_action_visible}
   abs_action: *abs_action
   tqdm_interval_sec: 1.0
-  n_envs: 28
+  n_envs: 12
 
 dataset:
   # _target_: equi_diffpo.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset
diff --git a/equi_diffpo/config/train_equi_diffusion_unet_rel.yaml b/equi_diffpo/config/train_equi_diffusion_unet_rel.yaml
index 3742ce0..790a997 100644
--- a/equi_diffpo/config/train_equi_diffusion_unet_rel.yaml
+++ b/equi_diffpo/config/train_equi_diffusion_unet_rel.yaml
@@ -1,6 +1,6 @@
 defaults:
   - _self_
-  - task: mimicgen_rel
+  - task: mimicgen_abs
 
 name: equi_diff
 _target_: equi_diffpo.workspace.train_equi_workspace.TrainEquiWorkspace
@@ -17,10 +17,13 @@ n_latency_steps: 0
 dataset_obs_steps: ${n_obs_steps}
 past_action_visible: False
 dataset: equi_diffpo.dataset.robomimic_replay_image_sym_dataset.RobomimicReplayImageSymDataset
-dataset_path: data/robomimic/datasets/${task_name}/${task_name}.hdf5
+dataset_path: ../../data/${task_name}/${task_name}.hdf5
+seed: 0
+
+
 
 policy:
-  _target_: equi_diffpo.policy.diffusion_equi_unet_cnn_enc_rel_policy.DiffusionEquiUNetCNNEncRelPolicy
+  _target_: equi_diffpo.policy.diffusion_equi_unet_cnn_enc_policy.DiffusionEquiUNetCNNEncPolicy
 
   shape_meta: ${shape_meta}
   
@@ -46,6 +49,7 @@ policy:
   kernel_size: 5
   n_groups: 8
   cond_predict_scale: True
+  rot_aug: False
 
   # scheduler.step params
   # predict_epsilon: True
@@ -81,7 +85,7 @@ optimizer:
 
 training:
   device: "cuda:0"
-  seed: 0
+  seed: ${seed}
   debug: False
   resume: True
   # optimization
@@ -105,7 +109,7 @@ training:
   tqdm_interval_sec: 1.0
 
 logging:
-  project: diffusion_policy_${task_name}_vel
+  project: diffusion_policy_${task_name}
   resume: True
   mode: online
   name: equidiff_demo${n_demo}
diff --git a/equi_diffpo/env_runner/robomimic_image_runner.py b/equi_diffpo/env_runner/robomimic_image_runner.py
index 70dcd15..7ea261a 100644
--- a/equi_diffpo/env_runner/robomimic_image_runner.py
+++ b/equi_diffpo/env_runner/robomimic_image_runner.py
@@ -22,7 +22,7 @@ from equi_diffpo.env.robomimic.robomimic_image_wrapper import RobomimicImageWrap
 import robomimic.utils.file_utils as FileUtils
 import robomimic.utils.env_utils as EnvUtils
 import robomimic.utils.obs_utils as ObsUtils
-
+import mimicgen
 
 def create_env(env_meta, shape_meta, enable_render=True):
     modality_mapping = collections.defaultdict(list)
diff --git a/equi_diffpo/scripts/robomimic_dataset_conversion.py b/equi_diffpo/scripts/robomimic_dataset_conversion.py
index dd4adb1..1b97ad1 100644
--- a/equi_diffpo/scripts/robomimic_dataset_conversion.py
+++ b/equi_diffpo/scripts/robomimic_dataset_conversion.py
@@ -16,6 +16,8 @@ from tqdm import tqdm
 import collections
 import pickle
 from equi_diffpo.common.robomimic_util import RobomimicAbsoluteActionConverter
+import mimicgen
+
 
 def worker(x):
     path, idx, do_eval = x
@@ -28,14 +30,15 @@ def worker(x):
     return abs_actions, info
 
 @click.command()
-@click.option('-i', '--input', required=True, help='input hdf5 path')
-@click.option('-o', '--output', required=True, help='output hdf5 path. Parent directory must exist')
-@click.option('-e', '--eval_dir', default=None, help='directory to output evaluation metrics')
-@click.option('-n', '--num_workers', default=None, type=int)
-def main(input, output, eval_dir, num_workers):
+@click.option("-i", "--input_file", required=True, help="input hdf5 path")
+@click.option("-o", "--output", required=True, help="output hdf5 path")
+@click.option("-e", "--eval_dir", default=None, help="directory to output evaluation metrics")
+@click.option("-b", "--batch_size", default=50, type=int)
+@click.option("-n", "--num_demos", default=200, type=int)
+def main(input_file, output, eval_dir, num_demos, batch_size):
     # process inputs
-    input = pathlib.Path(input).expanduser()
-    assert input.is_file()
+    input_file = pathlib.Path(input_file).expanduser()
+    assert input_file.is_file()
     output = pathlib.Path(output).expanduser()
     assert output.parent.is_dir()
     assert not output.is_dir()
@@ -46,15 +49,26 @@ def main(input, output, eval_dir, num_workers):
         assert eval_dir.parent.exists()
         do_eval = True
     
-    converter = RobomimicAbsoluteActionConverter(input)
+    converter = RobomimicAbsoluteActionConverter(input_file)
+    if num_demos is None:
+        num_demos = len(converter)
+    batch_size = num_demos if batch_size is None else batch_size
+    all_indices = list(range(num_demos))
+    results = []
+
+    for i in range(0, num_demos, batch_size):
+        batch = all_indices[i : i + batch_size]
+        print(
+            f"Processing batch {i // batch_size + 1} / {(num_demos + batch_size - 1) // batch_size}..."
+        )
+
+        with multiprocessing.Pool(processes=batch_size) as pool:
+            batch_results = pool.map(worker, [(input_file, idx, do_eval) for idx in batch])
+            results.extend(batch_results)
 
-    # run
-    with multiprocessing.Pool(num_workers) as pool:
-        results = pool.map(worker, [(input, i, do_eval) for i in range(len(converter))])
-    
     # save output
     print('Copying hdf5')
-    shutil.copy(str(input), str(output))
+    shutil.copy(str(input_file), str(output))
 
     # modify action
     with h5py.File(output, 'r+') as out_file:
